{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Load your Libraries\n",
    "All the libraries listed below are required to run this notebook.  \n",
    "\n",
    "If you require a GPU to train your model (for example, you are training a deep learning model), use DEFAULT_GPU_IMAGE instead of DEFAULT_CPU_IMAGE.  \n",
    "\n",
    "You can also modify the Hyperparameter run with some of the optional functions following this documentation: [hyperparameter tuning](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "\n",
    "root_folder = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "\n",
    "if root_folder != '/home/brandon/projects/aml/tAMLplates':\n",
    "    os.chdir('/home/brandon/projects/aml/tAMLplates')\n",
    "else:\n",
    "    os.chdir(root_folder)\n",
    "reuse_prior_run = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print(root_folder)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/brandon/projects/aml/e2eml\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Import Python Libraries\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "# Load Azure libaries\n",
    "import azureml.core\n",
    "from azureml.core import Datastore, Dataset, Environment, Experiment, Model, ScriptRunConfig, Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.runconfig import CondaDependencies, DEFAULT_CPU_IMAGE, RunConfiguration\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, PipelineEndpoint, PipelineParameter, PipelineRun\n",
    "from azureml.pipeline.core import PublishedPipeline, StepSequence, TrainingOutput\n",
    "from azureml.pipeline.steps import PythonScriptStep, HyperDriveStep\n",
    "from azureml.train.hyperdrive import HyperDriveRun, HyperDriveConfig, PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive import BayesianParameterSampling, uniform, choice\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Modify this workbook with some of the optional Azure libraries below\n",
    "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n",
    "from azureml.train.hyperdrive import normal, GridParameterSampling, RandomParameterSampling\n",
    "from azureml.train.hyperdrive import BanditPolicy, MedianStoppingPolicy, TruncationSelectionPolicy\n",
    "\n",
    "# utility scripts and yaml files\n",
    "from ml_service.util.env_variables import Env\n",
    "from ml_service.util.attach_compute import get_compute"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Connect your Workspace\n",
    "When using an Azure Notebook, you must first connect it to your Azure Machine Learning Service to access objects within the Workspace.  \n",
    "\n",
    "Use the code below and follow the instructions to sign in.  \n",
    "\n",
    "Also, issues may arise if you are use a different version of the Azure ML SDK.  If you encounter errors, <b>install the version this notebook was created with</b>."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check which version of the AzureML SDK you are using\n",
    "print(\"You are currently using version \" + azureml.core.VERSION + \" of the Azure ML SDK\")\n",
    "print(\"This notebook was made using version 1.31.0 of the Azure ML SDK\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Connect your Jupyter Notebook Server to your AMLS Workspace\n",
    "e = Env()\n",
    "\n",
    "#ws = Workspace.from_config()\n",
    "ws = Workspace.get(\n",
    "    name=e.workspace_name,\n",
    "    subscription_id=os.getenv(\"MYSUBSCRIPTION\"),\n",
    "    resource_group=e.resource_group,\n",
    ")\n",
    "print(\"get_workspace:\")\n",
    "print(ws.name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set your Remote Compute Target\n",
    "\n",
    "When you submit this run, it will run on a cluster of virtual machines.  Specify the cluster below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "computeTarget = get_compute(ws, e.compute_name, e.vm_size)\n",
    "if computeTarget is not None:\n",
    "    print(\"Using Azure Machine Learning compute:\")\n",
    "    print(computeTarget)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create an Environment which contains all the libraries needed for your scripts\n",
    "When you submit this run, it will create a docker container using all of the packages you list in this object.\n",
    "\n",
    "If a package is available through both conda and pip, <b>use the conda version</b>, as conda automatically reconciles package discrepancies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# To find out which packages are available in Conda, uncomment and run the code below\n",
    "#%conda list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Give your environment a name\n",
    "environment = Environment(name=\"XGBoostTrainingEnv\") # CHANGE HERE\n",
    "#condaDep = CondaDependencies()\n",
    "\n",
    "# Add conda packages\n",
    "# CHANGE HERE TO MATCH SCRIPT\n",
    "\n",
    "condaDep = CondaDependencies.create(\n",
    "    conda_packages=[\n",
    "        \"scikit-learn==0.22.1\",\n",
    "        \"numpy==1.16.2\",\n",
    "        \"matplotlib==3.2.1\",\n",
    "        \"joblib==0.14.1\",\n",
    "        \"xgboost==0.90\",\n",
    "        \"seaborn==0.9.0\",\n",
    "        \"pandas==0.23.4\",\n",
    "        \"scipy==1.3.1\",'pip'],\n",
    "    pip_packages=[\n",
    "        \"azureml-defaults==1.31.0\",\n",
    "        \"azureml-interpret==1.31.0\",\n",
    "        \"azureml-explain-model==1.31.0\",\n",
    "        \"pyarrow==1.0.1\",\n",
    "        \"pytz==2021.1\",\n",
    "        \"interpret-core==0.1.21\",\n",
    "        \"lightgbm==2.3.0\",\n",
    "        'openpyxl'])\n",
    "\n",
    "# Adds dependencies to PythonSection of myenv\n",
    "environment.python.conda_dependencies=condaDep\n",
    "\n",
    "# Register the environment to your workspace\n",
    "trainingEnvironment = environment.register(workspace=ws)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a Run Configuration object to dockerize your environment\n",
    "runConfig = RunConfiguration()\n",
    "runConfig.docker.use_docker = True\n",
    "runConfig.environment = environment\n",
    "runConfig.environment.docker.base_image = DEFAULT_CPU_IMAGE "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Dataset Registration, Training, Model Registration, and Metrics Output Scripts for your Pipeline\n",
    "When you run this pipeline, it will run a series of .py scripts.  Specify the folder name and file names of your scripts here."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a folder on your Jupyter Notebook server to store your .py files.\n",
    "projectFolder = e.projectFolder\n",
    "scriptFolder = e.scriptFolder\n",
    "os.makedirs(projectFolder, exist_ok=True)\n",
    "\n",
    "# Create file path strings\n",
    "# sharedFunctionsFilePath = os.path.join(projectFolder, \"training\", e.sharedFunctionsFileName)\n",
    "# unitTestingFilePath = os.path.join(projectFolder, \"training\", e.unitTestingFileName)\n",
    "# datasetRegistrationFilePath = os.path.join(projectFolder, \"training\", e.datasetRegistrationFileName)\n",
    "# trainingFilePath = os.path.join(projectFolder, \"training\", e.trainingFileName)\n",
    "# modelRegistrationFilePath = os.path.join(projectFolder, \"training\", e.modelRegistrationFileName)\n",
    "# metricsOutputFilePath = os.path.join(projectFolder, \"training\", e.metricsOutputFileName)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create or set datastore for saving data\n",
    "\n",
    "In the following steps you will be using the defined datastore from the environment configuration file or the default blob store that comes with Azure Machine Learning Service. You will then proceed to work with the defined dataset if it exists or upload a document to defined datastore and register the dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if e.datastore_name:\n",
    "    datastore_name = e.datastore_name\n",
    "else:\n",
    "    datastore_name = ws.get_default_datastore().name\n",
    "\n",
    "runConfig.environment.environment_variables[\"DATASTORE_NAME\"] = datastore_name\n",
    "print(datastore_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_name = e.dataset_name\n",
    "\n",
    "if dataset_name not in ws.datasets:\n",
    "\n",
    "    # Use a CSV to read in the data set.\n",
    "    print(os.getcwd())\n",
    "    path_to_local_folder = os.path.join(\"..\",\"data\")\n",
    "    \n",
    "    target_path = \"XGB/XGB_Training_Input\"\n",
    "    file_name = \"processed.cleveland.data.csv\"\n",
    "\n",
    "    path_and_file = os.path.join(path_to_local_folder, file_name)\n",
    "\n",
    "    if not os.path.exists(path_and_file):\n",
    "        raise Exception(\n",
    "            'Could not find CSV dataset at \"%s\".'\n",
    "            % file_name\n",
    "        )  # NOQA: E501\n",
    "\n",
    "    # Upload file to default datastore in workspace\n",
    "    datatstore = Datastore.get(ws, datastore_name)\n",
    "    datatstore.upload_files(\n",
    "        files=[file_name],\n",
    "        target_path=target_path,\n",
    "        overwrite=True,\n",
    "        show_progress=False,\n",
    "    )\n",
    "\n",
    "    # Register dataset\n",
    "    path_on_datastore = os.path.join(target_path, os.path.basename(file_name))\n",
    "\n",
    "    dataset = Dataset.Tabular.from_delimited_files(\n",
    "        path=(datatstore, path_on_datastore)\n",
    "    )\n",
    "\n",
    "    dataset = dataset.register(\n",
    "        workspace=ws,\n",
    "        name=dataset_name,\n",
    "        description=\"heart disease training data\",\n",
    "        tags={\"format\": \"CSV\", \"ml type\": \"multi-class classification\"},\n",
    "        create_new_version=True,\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set Pipeline Data to pass Best Model to Model Registration Step\n",
    "Pipeline data will be used to pass in combined metrics for all Hyperdrive runs along with the model and explaination for that <b>highest performing model</b>."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get your datastore\n",
    "datastore = Datastore.get(ws, datastore_name)\n",
    "\n",
    "# Hyperdrive Metrics\n",
    "metricsOutputName = 'metrics_output'\n",
    "metricsData = PipelineData(name = 'metrics_data',\n",
    "                           datastore = datastore,\n",
    "                           pipeline_output_name = metricsOutputName,\n",
    "                           training_output = TrainingOutput(\"Metrics\"))\n",
    "\n",
    "# Hyperdrive Best Model\n",
    "modelOutputName = 'model_output'\n",
    "savedModel = PipelineData(name = 'saved_model',\n",
    "                          datastore = datastore,\n",
    "                          pipeline_output_name = modelOutputName,\n",
    "                          training_output = TrainingOutput(\"Model\", model_file=\"outputs/XGBmodel.pkl\"))\n",
    "\n",
    "# Hyperdrive Best Model Explanations\n",
    "explainerOutputName = 'explainer_output'\n",
    "explainerModel = PipelineData(name = 'explainer_model',\n",
    "                              datastore = datastore,\n",
    "                              pipeline_output_name = explainerOutputName,\n",
    "                              training_output = TrainingOutput(\"Model\", model_file=\"outputs/LGBMexplainer.pkl\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set your Pipeline Parameters\n",
    "These are all the parameters you can use to easily adapt this code to other projects."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dataset Registration Step Parameters\n",
    "train_dataset_name_param = PipelineParameter(name=\"TrainDatasetName\", default_value='None')\n",
    "val_dataset_name_param = PipelineParameter(name=\"ValDatasetName\", default_value='None')\n",
    "datastore_name_param = PipelineParameter(name=\"DatastoreName\", default_value='None')\n",
    "datastore_path_param = PipelineParameter(name=\"DatastorePath\", default_value='None')\n",
    "train_file_name_param = PipelineParameter(name=\"TrainFileName\", default_value='None')\n",
    "original_file_name_param = PipelineParameter(name=\"OriginalData\", default_value='None')\n",
    "\n",
    "val_file_name_param = PipelineParameter(name=\"ValFileName\", default_value='None')\n",
    "project_name_param = PipelineParameter(name=\"ProjectName\", default_value='None')\n",
    "project_description_param = PipelineParameter(name=\"ProjectDescription\", default_value='None')\n",
    "pytz_time_zone_param = PipelineParameter(name='PytzTimeZone', default_value='UTC')\n",
    "\n",
    "# Hyperdrive Step Parameters\n",
    "target_column_param = PipelineParameter(name=\"TargetColumn\", default_value='None')\n",
    "k_folds_param = PipelineParameter(name=\"KFolds\", default_value=10)\n",
    "shuffle_split_size_param = PipelineParameter(name=\"ShuffleSplitSize\", default_value=0.1)\n",
    "confidence_level_param = PipelineParameter(name=\"ConfidenceLevel\", default_value = 0.95)\n",
    "\n",
    "# Model Registration Step Parameters\n",
    "model_name_param = PipelineParameter(name=\"ModelName\", default_value='None')\n",
    "output_path_param = PipelineParameter(name=\"OutputPath\", default_value='None')\n",
    "scoring_metric_param = PipelineParameter(name=\"ScoringMetric\", default_value='None')\n",
    "metric_goal_param = PipelineParameter(name=\"MetricGoal\", default_value='MAXIMIZE')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "splitData = PythonScriptStep(\n",
    "    name = \"split-data\",\n",
    "    source_directory = projectFolder,\n",
    "    script_name = 'split/split_data.py',\n",
    "    arguments=[\n",
    "        \"--folder_name\", datastore_path_param,\n",
    "        \"--file_name\", original_file_name_param,\n",
    "        \"--datastore_name\", datastore_name_param,\n",
    "        \"--train_file_name\", train_file_name_param,\n",
    "        \"--val_file_name\", val_file_name_param,\n",
    "        \"--label_name\", target_column_param,\n",
    "        \"--train_size\", \"0.80\"],\n",
    "    compute_target=computeTarget,\n",
    "    runconfig=runConfig,\n",
    "    allow_reuse=reuse_prior_run)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configure your Unit Testing Step\n",
    "Configure your unit testing step by specifing the folder and file names, the docker container run configuration, and the remote compute target."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "unit_test_folder = os.path.join(projectFolder,\"clusterScripts\")\n",
    "script_name = os.path.join(\"util\",e.unitTestingFileName)\n",
    "unitTestingStep = PythonScriptStep(\n",
    "    name = \"unit-testing-step\",\n",
    "    source_directory = unit_test_folder,\n",
    "    script_name = script_name,\n",
    "    arguments=[],\n",
    "    compute_target=computeTarget,\n",
    "    runconfig=runConfig,\n",
    "    allow_reuse=reuse_prior_run)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configure your Dataset Registration Step\n",
    "Configure your data registration step by specifing the folder and file names, the docker container run configuration, the remote compute target, and parameter arguments."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "register_folder = os.path.join(projectFolder,\"clusterScripts\")\n",
    "script_name = os.path.join(\"register\",e.datasetRegistrationFileName)\n",
    "datasetRegistrationStep = PythonScriptStep(\n",
    "    name = \"dataset-registration-step\",\n",
    "    source_directory = register_folder,\n",
    "    script_name = script_name,\n",
    "    arguments=['--train_dataset_name', train_dataset_name_param,\n",
    "               '--val_dataset_name', val_dataset_name_param,\n",
    "               '--datastore_name', datastore_name_param,\n",
    "               '--datastore_path', datastore_path_param,\n",
    "               '--train_file_name', train_file_name_param,\n",
    "               '--val_file_name', val_file_name_param,\n",
    "               '--project_name', project_name_param,\n",
    "               '--project_description', project_description_param,\n",
    "               '--pytz_time_zone', pytz_time_zone_param],\n",
    "    compute_target=computeTarget,\n",
    "    runconfig=runConfig,\n",
    "    allow_reuse=reuse_prior_run)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configure your Hyperdrive Step\n",
    "Configure your Hyperdrive registration step by specifing the folder and file names, the run environment, the remote compute target and parameter arguments.  \n",
    "\n",
    "Then, specify which <b>hyperparameters</b> you'd like to tune and the values that should be tested.\n",
    "\n",
    "Next, set the scoring metric and whether that metric should be minimized or maximized, along with the desired number of runs to tune your model.\n",
    "\n",
    "Finally, configure the step to output the best model, the best model explainer, and hyperdrive metrics data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set your script run configuration\n",
    "training_folder = os.path.join(projectFolder, \"clusterScripts\")\n",
    "script_name = os.path.join(\"training\",e.trainingFileName)\n",
    "scriptRunConfig = ScriptRunConfig(source_directory = training_folder,\n",
    "                  script = script_name,\n",
    "                  compute_target = computeTarget,\n",
    "                  environment = environment,\n",
    "                  arguments = ['--train_dataset_name', train_dataset_name_param,\n",
    "                               '--val_dataset_name', val_dataset_name_param,\n",
    "                               '--target_column_name', target_column_param,\n",
    "                               '--k_folds', k_folds_param,\n",
    "                               '--shuffle_split_size', shuffle_split_size_param,\n",
    "                               '--confidence_level', confidence_level_param])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hyperParams = BayesianParameterSampling({\n",
    "                        '--eta': uniform(0.01, 0.5),\n",
    "                        '--learning_rate': uniform(0.01,0.5),\n",
    "                        '--min_child_weight': uniform(1,100),\n",
    "                        '--max_depth': choice(range(3,11)),\n",
    "                        '--gamma': uniform(0,10),\n",
    "                        '--subsample': uniform(0.5,1),\n",
    "                        '--colsample_bytree': uniform(0.5,1),\n",
    "                        '--reg_lambda': uniform(0,10),\n",
    "                        '--alpha': uniform(0,10),\n",
    "                        '--scale_pos_weight': uniform(0,10),\n",
    "                        })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set your Hyperdrive configurations \n",
    "scoringMetric = 'Balanced Accuracy Training'\n",
    "metricGoal = PrimaryMetricGoal.MAXIMIZE\n",
    "metricGoalString = str(metricGoal)[18:]\n",
    "hyperdriveConfig = HyperDriveConfig(run_config = scriptRunConfig,\n",
    "                                     hyperparameter_sampling = hyperParams,\n",
    "                                     primary_metric_name = scoringMetric,\n",
    "                                     primary_metric_goal = metricGoal, # MAXIMIZE OR MINIMIZE\n",
    "                                     max_total_runs = 20,      # should be >= 20 times number of Hyperparameters\n",
    "                                     max_concurrent_runs = 20)  # should be 20 for Bayesian Sampling"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Configure your Hyperdrive Step\n",
    "hyperdriveTrainingStep = HyperDriveStep(\n",
    "    name = 'xgb-model-training-step-with-hyperparameter-tuning',\n",
    "    hyperdrive_config = hyperdriveConfig,\n",
    "    inputs = [],\n",
    "    outputs = [metricsData, savedModel, explainerModel],\n",
    "    allow_reuse = reuse_prior_run)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configure your Model Registration Step\n",
    "Configure your model registration step by specifing the folder and file names, the docker container run configuration, the remote compute target, and parameter arguments.\n",
    "\n",
    "Also, take in the best model, best model explanation, and hyperdrive metrics data as input into this step."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "script_name = os.path.join(\"register\", e.modelRegistrationFileName)\n",
    "modelRegistrationStep = PythonScriptStep(\n",
    "    name = \"model-registration-step\",\n",
    "    source_directory = register_folder,\n",
    "    script_name = script_name,\n",
    "    inputs = [savedModel, explainerModel, metricsData],\n",
    "    arguments = ['--train_dataset_name', train_dataset_name_param,\n",
    "                 '--val_dataset_name', val_dataset_name_param,\n",
    "                 '--datastore_name', datastore_name_param,\n",
    "                 '--project_name', project_name_param,\n",
    "                 '--project_description', project_description_param,\n",
    "                 '--pytz_time_zone', pytz_time_zone_param,\n",
    "                 '--target_column_name', target_column_param,\n",
    "                 '--k_folds', k_folds_param,\n",
    "                 '--confidence_level', confidence_level_param,\n",
    "                 '--model_name', model_name_param,\n",
    "                 '--output_path', output_path_param,\n",
    "                 '--scoring_metric', scoring_metric_param,\n",
    "                 '--metric_goal', metric_goal_param,\n",
    "                 '--saved_model', savedModel,\n",
    "                 '--explainer_model', explainerModel,\n",
    "                 '--metrics_data', metricsData],\n",
    "    compute_target = computeTarget,\n",
    "    runconfig = runConfig,\n",
    "    allow_reuse = reuse_prior_run)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configure your Hyperdrive Run Metrics Output Step\n",
    "Configure your metrics output step by specifing the folder and file names, the docker container run configuration, the remote compute target, and parameter arguments.\n",
    "\n",
    "Also, take in the hyperdrive metrics data as input into this step."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "metrics_folder = os.path.join(projectFolder,\"clusterScripts\")\n",
    "script_name = os.path.join(\"metrics\", e.metricsOutputFileName )\n",
    "\n",
    "metricsOutputStep = PythonScriptStep(\n",
    "    name = \"metrics-output-step\",\n",
    "    source_directory = metrics_folder,\n",
    "    script_name = script_name,\n",
    "    inputs = [metricsData],\n",
    "    arguments = ['--datastore_name', datastore_name_param,\n",
    "                 '--pytz_time_zone', pytz_time_zone_param,\n",
    "                 '--output_path', output_path_param,\n",
    "                 '--scoring_metric', scoring_metric_param,\n",
    "                 '--metrics_data', metricsData],\n",
    "    compute_target = computeTarget,\n",
    "    runconfig = runConfig,\n",
    "    allow_reuse = reuse_prior_run\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run your Five-Step Pipeline\n",
    "Specify the order in which to run your steps.  Then, pass in your parameters and <b>submit</b> your pipeline."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create your pipeline\n",
    "parallelSteps = [modelRegistrationStep, metricsOutputStep]\n",
    "stepSequence = StepSequence(steps = [unitTestingStep, splitData, datasetRegistrationStep, hyperdriveTrainingStep, parallelSteps])\n",
    "pipeline = Pipeline(workspace = ws, steps = stepSequence)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Parameter Explanation\n",
    "<p><b>TrainDatasetName:</b> Name of your registered training dataset.  This can be anything you would like.</p>\n",
    "<p><b>ValDatasetName:</b> Name of your registered validation dataset.  This can be anything you would like.</p>\n",
    "<p><b>DatastoreName:</b> Name of your datastore.  This should be the datastore that holds your input data.</p>\n",
    "<p><b>DatastorePath:</b> Root folder path which holds your data up to today's date.</p>\n",
    "<p><b>TrainFileName:</b> Name of your training file located in your datastore.</p>\n",
    "<p><b>ValFileName:</b> Name of your validation file located in your datastore.</p>\n",
    "<p><b>ProjectName:</b> Name of your project.  This can be anything you would like.</p>\n",
    "<p><b>ProjectDescription:</b> Description of your project.  This can be anything you would like.</p>\n",
    "<p><b>PytzTimeZone:</b> Your timezone or the timezone in which the data is loaded.</p>\n",
    "<p><b>TargetColumn:</b> Name of your target column for machine learning.</p>\n",
    "<p><b>KFolds:</b> Number of times to split your data for cross validation.</p>\n",
    "<p><b>ShuffleSplitSize:</b> Percentage of data to split for cross validation.</p>\n",
    "<p><b>ConfidenceLevel:</b> Percentage used to create your confidence interval to compare validation and training results.</p>\n",
    "<p><b>ModelName:</b> Name of your registered model.  This can anything you like following the naming convention.</p>\n",
    "<p><b>OutputPath:</b> Root folder path to output your results on your datastore.</p>\n",
    "<p><b>ScoringMetric:</b> Metric you wish to maximize or minimize as part of hyperparameter tuning.  Set in the Hyperdrive pipeline step section.</p>\n",
    "<p><b>MetricGoal:</b> Whether you should minimize or maximize your Hyperparameter Metric.  Set in the Hyperdrive pipeline step section.</p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# To get a list of Pytz Time Zones, uncomment and run the code below\n",
    "#pytz.all_timezones"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run your pipeline\n",
    "pipelineName = 'XGB_Model_Training'\n",
    "pipeline_run = Experiment(ws, pipelineName).submit(pipeline,pipeline_parameters=\n",
    "                                                           {'TrainDatasetName': 'XGB Training Data',\n",
    "                                                           'ValDatasetName': 'XGB Validation Data',\n",
    "                                                           'DatastoreName': datastore_name,\n",
    "                                                           'DatastorePath': 'XGB/XGB_Training_Input',\n",
    "                                                           'TrainFileName': 'xgbTrainingData.csv',\n",
    "                                                           'ValFileName': 'xgbValidationData.csv',\n",
    "                                                           'OriginalData': 'processed.cleveland.data.csv',\n",
    "                                                           'ProjectName': 'XGB Test',\n",
    "                                                           'ProjectDescription': 'XGB Test Run',\n",
    "                                                           'PytzTimeZone': 'US/Eastern',\n",
    "                                                           'TargetColumn': 'num',\n",
    "                                                           'KFolds': 10,\n",
    "                                                           'ShuffleSplitSize': 0.1,\n",
    "                                                           'ConfidenceLevel': 0.95,\n",
    "                                                           'ModelName': 'Tuned-XGB-Model',\n",
    "                                                           'OutputPath': 'XGB/XGB_Training_Output',\n",
    "                                                           'ScoringMetric': scoringMetric,\n",
    "                                                           'MetricGoal': metricGoalString}, \n",
    "                                                           show_output=True)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# GUI to see your Pipeline Run\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Publish your Pipeline\n",
    "First, if you shutdown your notebook, use the first cell to retrieve your pipeline run.\n",
    "\n",
    "Second, publish your pipeline. \n",
    "\n",
    "Third, assign your published pipeline to a permanent endpoint.  \n",
    "\n",
    "You now have an endpoint you can easily schedule either in AMLS or through <b>Azure Data Factory</b>."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Retrieve a previously run pipeline if necessary by uncommenting and running the code below\n",
    "#experiment_name = 'XGB_Model_Training'\n",
    "#experiment = Experiment(ws, experiment_name)\n",
    "#pipeline_run = PipelineRun(experiment, 'your-pipeline-run-id')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Publish your Pipeline\n",
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"XGB_Model_Training\",\\\n",
    "    description=\"XGB Model Training Pipeline for ADF Use\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Attach your Published Pipeline to a Permanent Endpoint\n",
    "pipelineEndpointName = \"XGB Training Pipeline Endpoint\"\n",
    "\n",
    "if pipelineEndpointName in str(PipelineEndpoint.list(ws)):\n",
    "    # Add a new Version to an existing Endpoint\n",
    "    pipeline_endpoint = PipelineEndpoint.get(workspace = ws, name = pipelineEndpointName)\n",
    "    pipeline_endpoint.add_default(published_pipeline)\n",
    "else:\n",
    "    # Create a new Endpoint\n",
    "    pipeline_endpoint = PipelineEndpoint.publish(workspace = ws,\n",
    "                                                name = pipelineEndpointName,\n",
    "                                                pipeline = published_pipeline,\n",
    "                                                description = \"XGB Training Pipeline Endpoint\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit ('azureml': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "interpreter": {
   "hash": "7e83dc761fc988981533694a2311fa2ea3255fc5e002e7da84a6a977096f1034"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}